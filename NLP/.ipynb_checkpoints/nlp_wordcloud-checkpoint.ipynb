{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters, stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\TinkerBell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# Instantiate the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "crude_article = reuters.raw(fileids=reuters.fileids(categories='crude')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokenize(crude_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))\n",
    "sw_addon = {'said', 'mln', 'kilolitres','kl', 'also', 'could','would'}\n",
    "sw_union = sw.union(sw_addon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    " # define stopwording and regex \n",
    "def clean_text(article, swu):\n",
    "    #t_sentence = sent_tokenize(article)\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    re_clean = regex.sub('', article)\n",
    "    text_clean=[]\n",
    "    #for sent in t_sentence:\n",
    "    t_word=word_tokenize(re_clean)\n",
    "    first_pass= [word.lower() for word in t_word if word.lower() not in swu]\n",
    "    sec_pass = [lemmatizer.lemmatize(word, pos='a') for word in first_pass if len(word)>2]\n",
    "    #text_clean.append([regex.sub('', word) for word in sec_pass])\n",
    "    return sec_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_article = clean_text(crude_article, sw_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turkey', 4),\n",
       " ('greece', 3),\n",
       " ('statement', 3),\n",
       " ('two', 3),\n",
       " ('issue', 3),\n",
       " ('countries', 3),\n",
       " ('solve', 2),\n",
       " ('dispute', 2),\n",
       " ('today', 2),\n",
       " ('disputes', 2),\n",
       " ('rights', 2),\n",
       " ('continental', 2),\n",
       " ('shelf', 2),\n",
       " ('aegean', 2),\n",
       " ('solved', 2),\n",
       " ('negotiations', 2),\n",
       " ('foreign', 2),\n",
       " ('ministry', 2),\n",
       " ('late', 2),\n",
       " ('last', 2)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = Counter(tokenized_article)\n",
    "word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(('turkey', 'calls'), 1), (('calls', 'dialogue'), 1), (('dialogue', 'solve'), 1), (('solve', 'dispute'), 1), (('dispute', 'turkey'), 1), (('turkey', 'today'), 1), (('today', 'disputes'), 1), (('disputes', 'greece'), 1), (('greece', 'including'), 1), (('including', 'rights'), 1), (('rights', 'continental'), 1), (('continental', 'shelf'), 2), (('shelf', 'aegean'), 1), (('aegean', 'sea'), 1), (('sea', 'solved'), 1), (('solved', 'negotiations'), 1), (('negotiations', 'foreign'), 1), (('foreign', 'ministry'), 2), (('ministry', 'statement'), 2), (('statement', 'late'), 1), (('late', 'crisis'), 1), (('crisis', 'two'), 1), (('two', 'nato'), 1), (('nato', 'members'), 1), (('members', 'stemmed'), 1), (('stemmed', 'continental'), 1), (('shelf', 'dispute'), 1), (('dispute', 'agreement'), 1), (('agreement', 'issue'), 1), (('issue', 'effect'), 1), (('effect', 'security'), 1), (('security', 'economy'), 1), (('economy', 'rights'), 1), (('rights', 'countries'), 1), (('countries', 'issue'), 1), (('issue', 'basicly'), 1), (('basicly', 'political'), 1), (('political', 'solution'), 1), (('solution', 'found'), 1), (('found', 'bilateral'), 1), (('bilateral', 'negotiations'), 1), (('negotiations', 'statement'), 1), (('statement', 'greece'), 1), (('greece', 'repeatedly'), 1), (('repeatedly', 'issue'), 1), (('issue', 'legal'), 1), (('legal', 'solved'), 1), (('solved', 'international'), 1), (('international', 'court'), 1), (('court', 'justice'), 1), (('justice', 'two'), 1), (('two', 'countries'), 2), (('countries', 'approached'), 1), (('approached', 'armed'), 1), (('armed', 'confrontation'), 1), (('confrontation', 'last'), 1), (('last', 'month'), 1), (('month', 'greece'), 1), (('greece', 'announced'), 1), (('announced', 'planned'), 1), (('planned', 'oil'), 1), (('oil', 'exploration'), 1), (('exploration', 'work'), 1), (('work', 'aegean'), 1), (('aegean', 'turkey'), 1), (('turkey', 'search'), 1), (('search', 'oil'), 1), (('oil', 'faceoff'), 1), (('faceoff', 'averted'), 1), (('averted', 'turkey'), 1), (('turkey', 'confined'), 1), (('confined', 'research'), 1), (('research', 'territorrial'), 1), (('territorrial', 'waters'), 1), (('waters', 'late'), 1), (('late', 'crises'), 1), (('crises', 'created'), 1), (('created', 'historic'), 1), (('historic', 'opportunity'), 1), (('opportunity', 'solve'), 1), (('solve', 'disputes'), 1), (('disputes', 'two'), 1), (('countries', 'foreign'), 1), (('statement', 'turkeys'), 1), (('turkeys', 'ambassador'), 1), (('ambassador', 'athens'), 1), (('athens', 'nazmi'), 1), (('nazmi', 'akiman'), 1), (('akiman', 'due'), 1), (('due', 'meet'), 1), (('meet', 'prime'), 1), (('prime', 'minister'), 2), (('minister', 'andreas'), 1), (('andreas', 'papandreou'), 1), (('papandreou', 'today'), 1), (('today', 'greek'), 1), (('greek', 'reply'), 1), (('reply', 'message'), 1), (('message', 'sent'), 1), (('sent', 'last'), 1), (('last', 'week'), 1), (('week', 'turkish'), 1), (('turkish', 'prime'), 1), (('minister', 'turgut'), 1), (('turgut', 'ozal'), 1), (('ozal', 'contents'), 1), (('contents', 'message'), 1), (('message', 'disclosed'), 1)])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts = Counter(ngrams(tokenized_article, n=2))\n",
    "bigram_counts.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('continental', 'shelf'), 2),\n",
       " (('foreign', 'ministry'), 2),\n",
       " (('ministry', 'statement'), 2),\n",
       " (('two', 'countries'), 2),\n",
       " (('prime', 'minister'), 2),\n",
       " (('turkey', 'calls'), 1),\n",
       " (('calls', 'dialogue'), 1),\n",
       " (('dialogue', 'solve'), 1),\n",
       " (('solve', 'dispute'), 1),\n",
       " (('dispute', 'turkey'), 1)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_df = pd.DataFrame({'bigram': [key for key in bigram_counts.keys()], \n",
    "                          'frequency': [val for val in bigram_counts.values()]}, \n",
    "                           index=range(0, len(bigram_counts.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(continental, shelf)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(foreign, ministry)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(ministry, statement)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>(two, countries)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(prime, minister)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(turkey, calls)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(calls, dialogue)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(dialogue, solve)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(solve, dispute)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(dispute, turkey)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bigram  frequency\n",
       "11   (continental, shelf)          2\n",
       "17    (foreign, ministry)          2\n",
       "18  (ministry, statement)          2\n",
       "51       (two, countries)          2\n",
       "91      (prime, minister)          2\n",
       "0         (turkey, calls)          1\n",
       "1       (calls, dialogue)          1\n",
       "2       (dialogue, solve)          1\n",
       "3        (solve, dispute)          1\n",
       "4       (dispute, turkey)          1"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df.nlargest(10, 'frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
